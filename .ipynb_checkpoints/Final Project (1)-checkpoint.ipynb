{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b073f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotnine\n",
    "# !pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ee1ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans, KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.set(rc = {'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fcee469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_DBSCAN(df, eps, min_samples, plot=False):\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples).fit(df).labels_\n",
    "    hue = [str(i) for i in labels]\n",
    "    print(silhouette_score(df, labels))\n",
    "    if plot:\n",
    "        sns.scatterplot(x=df[:, 0], y=df[:, 1], hue=hue)\n",
    "        plt.show()\n",
    "    return labels\n",
    "\n",
    "def plot_KMeans(df, n_clusters, plot=False):\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(df)\n",
    "    hue = [str(i) for i in kmeans.labels_]\n",
    "    print(silhouette_score(df, kmeans.labels_))\n",
    "    if plot:\n",
    "        sns.scatterplot(x=df[:, 0], y=df[:, 1], hue=hue)\n",
    "        plt.show()\n",
    "    return kmeans.labels_\n",
    "\n",
    "\n",
    "def plot_Agg(df, n_clusters=2, plot=False):\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters).fit(df)\n",
    "    hue = [str(i) for i in clustering.labels_]\n",
    "    print(silhouette_score(df, clustering.labels_))\n",
    "    if plot:\n",
    "        sns.scatterplot(x=df[:, 0], y=df[:, 1], hue=hue)\n",
    "        plt.show()\n",
    "    return clustering.labels_\n",
    "\n",
    "def plot_gaussian(df_scaled, k):\n",
    "    gm = GaussianMixture(k)\n",
    "    gm.fit(df_scaled)\n",
    "    labels = gm.predict(df_scaled)\n",
    "    print(silhouette_score(df_scaled, labels))\n",
    "    return labels\n",
    "\n",
    "def elbow(df, k=7):\n",
    "    model = KElbowVisualizer(KMeans(), k=k)\n",
    "    model.fit(df)\n",
    "    model.show()\n",
    "\n",
    "\n",
    "def plot_1d(pca_df, labels):\n",
    "    sns.scatterplot(pca_df[:, 0], np.zeros_like(pca_df[:, 0]), hue=labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6877bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Data.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e04391cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d42b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6f7fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Analysis:\n",
    "    def view_dataset(self, df):\n",
    "        print(df.head())\n",
    "    def checkk_nan(self, df):\n",
    "        print(df.isna().sum())\n",
    "    \n",
    "    def remove_nan(self, df):\n",
    "        print(\"Shape of dataset before removing missing values: \", df.shape)\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"Shape of dataset after removing missing values: \", df.shape)\n",
    "        return df\n",
    "        \n",
    "da = Data_Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c907fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da.view_dataset(train_df)\n",
    "# da.checkk_nan(train_df)\n",
    "train_df = da.remove_nan(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8006807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf763d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccb7e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d44ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c6b69",
   "metadata": {},
   "source": [
    "<h1>Uni Variate Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c0939ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=train_df['Gender'])\n",
    "plt.title(\"Distributions of Gender\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=train_df['Ever_Married'])\n",
    "plt.title(\"Distributions of Ever Married\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9121b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df['Graduated'])\n",
    "plt.title(\"Distributions of Graduated\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08397ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df['Profession'])\n",
    "plt.title(\"Distributions of Profession\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd19f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = train_df, x='Age', kde=True, height=8, aspect=15/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1aafc2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(train_df['Work_Experience'])\n",
    "plt.title(\"Work Experience Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37d83c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(train_df['Family_Size'])\n",
    "plt.title(\"Family Size Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c052118",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df['Spending_Score'])\n",
    "plt.title(\"Spending Score Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c79b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df['Var_1'])\n",
    "plt.title(\"Variable Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f058570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Var_1'].value_counts().plot(kind=\"pie\",autopct=\"%.1f%%\")\n",
    "plt.title(\"Variable Distributions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f814a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df['Segmentation'])\n",
    "plt.title(\"Segmentation Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3984b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Segmentation'].value_counts().plot(kind=\"pie\",autopct=\"%.1f%%\")\n",
    "plt.title(\"Segmentation Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1240450",
   "metadata": {},
   "source": [
    "<h1>Bi-Variate Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b38db6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=train_df[['Age', 'Graduated', 'Work_Experience', 'Family_Size',\n",
    "       'Segmentation']],hue='Segmentation',palette=['Red','Blue','Green','Yellow']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1999b",
   "metadata": {},
   "source": [
    "<h1>Age</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8532b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['Age'].min())\n",
    "print(train_df['Age'].max())\n",
    "print(train_df['Age'].mean())\n",
    "print(train_df['Age'].median())\n",
    "print(train_df['Age'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96bdbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = train_df, x='Age', row='Profession', kde=True, height=8, aspect=15/8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0013a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = train_df.copy()\n",
    "dummy_df['Age'] = pd.cut(dummy_df['Age'],\n",
    "                     bins=[0, 15, 25, 35, 45, 55, 65, 75, 85, np.inf],\n",
    "                     labels=['0-15', '15-25', '25-35', '35-45', '45-55', '55-65', '65-75', '75-85', '85+'])\n",
    "\n",
    "# Convert 'Age' column to a categorical data type with the specified order\n",
    "age_order = ['0-15', '15-25', '25-35', '35-45', '45-55', '55-65', '65-75', '75-85', '85+']\n",
    "dummy_df['Age'] = pd.Categorical(dummy_df['Age'], categories=age_order, ordered=True)\n",
    "\n",
    "# Create a countplot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.set_title('Age Distribution', fontsize=20)\n",
    "\n",
    "# Sort the age ranges for better readability\n",
    "sns.countplot(x='Age', data=dummy_df, order=age_order)\n",
    "\n",
    "ax.set_ylabel('Number', fontsize=15)\n",
    "ax.set_xlabel('Age Ranges', fontsize=15)\n",
    "\n",
    "# Add percentage values on top of the bars\n",
    "total = len(dummy_df['Age'])\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n",
    "    x = p.get_x() + p.get_width() / 2 - 0.15\n",
    "    y = p.get_height() + 10\n",
    "    ax.annotate(percentage, (x, y), fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26022c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train_df, x='Gender', hue='Spending_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89f3eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = train_df, x='Profession', hue='Graduated')\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "260d6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = train_df, x='Profession', hue='Spending_Score')\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3cda5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = train_df, x='Family_Size', hue='Spending_Score')\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab99a5",
   "metadata": {},
   "source": [
    "<h2>Corelation ANalysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c0b2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87483fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "423f120f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ID', 'Var_1', 'Segmentation'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m train_df[make_cat] \u001b[38;5;241m=\u001b[39m OrdinalEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(train_df[make_cat])\n\u001b[0;32m     10\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVar_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_to_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m train_df\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ID', 'Var_1', 'Segmentation'] not found in axis\""
     ]
    }
   ],
   "source": [
    "make_cat = ['Profession', 'Spending_Score']\n",
    "make_dummies = ['Gender', 'Ever_Married', 'Graduated'] \n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=make_dummies)\n",
    "\n",
    "for col in make_cat:\n",
    "    train_df[col] =train_df[col].astype('category')\n",
    "\n",
    "train_df[make_cat] = OrdinalEncoder().fit_transform(train_df[make_cat])\n",
    "columns_to_drop = [\"ID\",\"Var_1\",\"Segmentation\"]\n",
    "train_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de7cd92c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Only a column name can be used for the key in a dtype mappings argument. 'Gender_Female' not found in columns.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGender_Female\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGender_Male\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEver_Married_No\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEver_Married_Yes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGraduated_No\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGraduated_Yes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(correlation_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:6498\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m dtype_ser\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m   6497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m-> 6498\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m   6499\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly a column name can be used for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6500\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey in a dtype mappings argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6501\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6502\u001b[0m         )\n\u001b[0;32m   6504\u001b[0m dtype_ser \u001b[38;5;241m=\u001b[39m dtype_ser\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6506\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Only a column name can be used for the key in a dtype mappings argument. 'Gender_Female' not found in columns.\""
     ]
    }
   ],
   "source": [
    "train_df = train_df.astype({'Gender_Female': int, 'Gender_Male': int, \"Ever_Married_No\": int, \"Ever_Married_Yes\": int, \"Graduated_No\": int,\"Graduated_Yes\": int})\n",
    "correlation_matrix = train_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', cbar=True, linewidths=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f097727",
   "metadata": {},
   "source": [
    "<h2>Outlier Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7604412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outlier_charT(column_name):\n",
    "    Q1 = train_df[column_name].quantile(0.25)\n",
    "    Q3 = train_df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = train_df[(train_df[column_name] < lower_bound) | (train_df[column_name] > upper_bound)]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train_df.index, train_df[column_name], label='Data')\n",
    "    plt.scatter(outliers.index, outliers[column_name], color='r', label='Outliers')\n",
    "    plt.axhline(y=lower_bound, color='g', linestyle='--', label='Lower Bound')\n",
    "    plt.axhline(y=upper_bound, color='g', linestyle='--', label='Upper Bound')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel(column_name)\n",
    "    plt.legend()\n",
    "    plt.title('Identifying and Plotting Outliers')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_outlier_charT(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_outlier_charT(\"Work_Experience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce838c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_outlier_charT(\"Spending_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_outlier_charT(\"Family_Size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fbf9f",
   "metadata": {},
   "source": [
    "<h2>Initiate clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f04da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data.csv\")\n",
    "df.dropna(inplace=True)\n",
    "make_dummies = ['Gender', 'Ever_Married', 'Graduated'] \n",
    "make_cat = ['Profession', 'Spending_Score']\n",
    "df = pd.get_dummies(df, columns=make_dummies)\n",
    "\n",
    "for col in make_cat:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df[make_cat] = OrdinalEncoder().fit_transform(df[make_cat])\n",
    "columns_to_drop = [\"ID\",\"Var_1\",\"Segmentation\"]\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(column_name, df):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[~((df[column_name] < lower_bound) | (df[column_name] > upper_bound))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(\"Age\", df)\n",
    "df = remove_outliers(\"Work_Experience\", df)\n",
    "df = remove_outliers(\"Family_Size\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33df1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca53c0",
   "metadata": {},
   "source": [
    "<h2>K Means Clustering Elbow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e90711",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Age', 'Profession', 'Work_Experience', 'Spending_Score', 'Family_Size']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columns_to_scale),\n",
    "        ('passthrough', 'passthrough', df.columns.difference(columns_to_scale).tolist())\n",
    "    ])\n",
    "scaled_data = preprocessor.fit_transform(df)\n",
    "# df = pd.DataFrame(scaled_data, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a67bc06",
   "metadata": {},
   "source": [
    "<h3>Implement PCA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c166f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "pc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637625cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow(pc_df, k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5dc12e",
   "metadata": {},
   "source": [
    "<h2>KMeans Visualization </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea559489",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6).fit(pc_df)\n",
    "hue = [str(i) for i in kmeans.labels_]\n",
    "print(silhouette_score(pc_df, kmeans.labels_))\n",
    "sns.scatterplot(x=pc_df.iloc[:, 0], y=pc_df.iloc[:, 1], hue=hue)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49111a",
   "metadata": {},
   "source": [
    "<h2>Agglomorative Clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(2, 11):\n",
    "    clustering = AgglomerativeClustering(n_clusters=i).fit(pc_df)\n",
    "    x.append(silhouette_score(pc_df, clustering.labels_))\n",
    "    y.append(i)\n",
    "\n",
    "plt.plot(y, x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=8).fit(pc_df)\n",
    "hue = [str(i) for i in clustering.labels_]\n",
    "print(silhouette_score(pc_df, clustering.labels_))\n",
    "sns.scatterplot(x=pc_df.iloc[:, 0], y=pc_df.iloc[:, 1], hue=hue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b8bb4",
   "metadata": {},
   "source": [
    "<h2>DBSCAN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.arange(1, 2, 0.02)\n",
    "silhouettes = np.zeros(shape=(len(epsilons), 2))\n",
    "index = 0\n",
    "for i in epsilons:\n",
    "    eps = round(i, 2)\n",
    "    labels = DBSCAN(eps=eps, min_samples=20).fit(pc_df).labels_\n",
    "    silhouettes[index, 0] = eps\n",
    "    silhouettes[index, 1] = silhouette_score(pc_df, labels)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f712b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(silhouettes[:, 0], silhouettes[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = DBSCAN(eps=2, min_samples=4).fit(pc_df).labels_\n",
    "hue = [str(i) for i in labels]\n",
    "print(silhouette_score(pc_df, labels))\n",
    "sns.scatterplot(x=pc_df.iloc[:, 0], y=pc_df.iloc[:, 1], hue=hue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b935fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
